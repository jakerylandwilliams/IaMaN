{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's a Machine and Natural Language Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading post-training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 473.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gold-tagged UDs data...\n",
      "Avail. post-train, total post-train, Avail. gold, total gold-train, total test-gold:  14198 1000 150 132 18\n"
     ]
    }
   ],
   "source": [
    "from src.IaMaN.base import LM\n",
    "from src.utils.data import load_ud\n",
    "from src.utils.munge import stick_spaces\n",
    "from pprint import pprint as pprint\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "seed = 691; max_char = 200_000_000\n",
    "m = 10; space = True; fine_tune = False; num_posttrain = 1000; noise = 0.001\n",
    "positional = 'dependent'; positionally_encode = True; bits = 50; btype = 'all'\n",
    "ms_init = 'waiting_time'; update = {'representation', 'contexts', 'tokenizer'}\n",
    "runners = 10; gpu = False; tokenizer = 'hr-bpe'; decode_method = 'argmax'\n",
    "\n",
    "print(\"Loading post-training data...\")\n",
    "posttrain_path = '/data/newstweet/week_2019-40_article_texts/'\n",
    "total_posttrain = len([posttrain_file for posttrain_file in os.listdir(posttrain_path) if re.search(\"^\\d+.txt$\", posttrain_file)])\n",
    "all_posttrain_files = [posttrain_file for posttrain_file in os.listdir(posttrain_path) if re.search(\"^\\d+.txt$\", posttrain_file)]\n",
    "if num_posttrain:\n",
    "    np.random.seed(seed)\n",
    "    posttrain_files = np.random.choice(all_posttrain_files, size=num_posttrain, replace=False)\n",
    "else:\n",
    "    posttrain_files = np.array([])\n",
    "ptdocs = [[open(posttrain_path+posttrain_file).read()] for posttrain_file in tqdm(posttrain_files)]\n",
    "print(\"Loading gold-tagged UDs data...\")\n",
    "load_set = \"GUM\"\n",
    "all_docs = load_ud(\"English\", num_articles = 0, seed = seed, load_set = load_set, rebuild = True, space = space)\n",
    "test_docs = [doc for doc in all_docs if 'test' in doc['id'] and len(doc['text']) <= max_char]# [:2]\n",
    "train_docs = [doc for doc in all_docs if 'test' not in doc['id'] and len(doc['text']) <= max_char]# [:4]\n",
    "nsamp = len(test_docs)\n",
    "print('Avail. post-train, total post-train, Avail. gold, total gold-train, total test-gold: ', \n",
    "      total_posttrain, len(ptdocs), len(all_docs), len(train_docs), len(test_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing: 100%|██████████| 6503/6503 [00:01<00:00, 4462.22it/s]\n",
      "Fitting:  20%|██        | 20/100 [00:43<02:53,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built a vocabulary of 15327 types\n",
      "Pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-processed data: 100%|██████████| 132/132 [00:00<00:00, 978176.90it/s]\n",
      "Counting tag-tag transition frequencies: 100%|██████████| 132/132 [00:00<00:00, 224.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting documents and aggregating counts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting aggregated counts: 5082533it [03:34, 23669.27it/s] \n",
      "Encoding parameters: 100%|██████████| 5082533/5082533 [00:51<00:00, 97986.09it/s] \n",
      "Building target vocabularies: 100%|██████████| 23/23 [00:00<00:00, 1020.94it/s]\n",
      "Stacking output vocabularies for decoders: 100%|██████████| 11/11 [00:00<00:00, 87381.33it/s]\n",
      "Building dense decoders: 100%|██████████| 23/23 [00:00<00:00, 32.24it/s]\n",
      "Building transition matrices for tag-sequence decoding:   0%|          | 0/7 [00:00<?, ?it/s]/code/IaMaN/src/IaMaN/base.py:673: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self._trXs[ltype] = (lambda M: M/M.sum(axis = 1)[:,None])(self._trXs[ltype])\n",
      "Building transition matrices for tag-sequence decoding: 100%|██████████| 7/7 [00:00<00:00, 3097.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params, types, encoding size, contexts, vec dim, max sent, and % capacity used: 886810 10568 50 1071 353 258 9.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs = [[\"\".join([row[1] for row in s]) for s in d['conllu']] for d in train_docs]\n",
    "tdocs = [[\"\".join([row[1] for row in s]) for s in d['conllu']] for d in test_docs]\n",
    "covering = [[[row[1] for row in s] for s in d['conllu']] for d in train_docs]\n",
    "tcovering = [[[row[1] for row in s] for s in d['conllu']] for d in test_docs]\n",
    "if not space:\n",
    "    for d_i, d in enumerate(covering):\n",
    "        for s_i, s in enumerate(d):\n",
    "            covering[d_i][s_i] = stick_spaces(s)\n",
    "    for d_i, d in enumerate(tcovering):\n",
    "        for s_i, s in enumerate(d):\n",
    "            tcovering[d_i][s_i] = stick_spaces(s)\n",
    "covering_vocab = set([t for d in covering for s in d for t in s])\n",
    "\n",
    "# 'lem': [[row[2] for row in s] for s in d['conllu']], # note: for speed, remove lemma layer\n",
    "train_layers = {d_i: {'sty': [[d['s_type'][s_i] for row in s] for s_i, s in enumerate(d['conllu'])], \n",
    "                      'pos': [[row[3] for row in s] for s in d['conllu']], \n",
    "                      'sup': [[(str(int(row[6]) - int(row[0])) if int(row[6]) else row[6]) for row in s] for s in d['conllu']], \n",
    "                      'dep': [[row[7] for row in s] for s in d['conllu']]}\n",
    "                for d_i, d in enumerate(train_docs)}\n",
    "# 'lem': [[row[2] for row in s] for s in d['conllu']], # note: for speed, remove lemma layer\n",
    "test_layers = {d_i: {'sty': [[d['s_type'][s_i] for row in s] for s_i, s in enumerate(d['conllu'])], \n",
    "                     'pos': [[row[3] for row in s] for s in d['conllu']], \n",
    "                     'sup': [[(str(int(row[6]) - int(row[0])) if int(row[6]) else row[6]) for row in s] for s in d['conllu']], \n",
    "                     'dep': [[row[7] for row in s] for s in d['conllu']]}\n",
    "               for d_i, d in enumerate(test_docs)}\n",
    "\n",
    "model = LM(m = m, tokenizer = tokenizer, noise = noise, seed = seed, space = space, positional = positional,\n",
    "           positionally_encode = positionally_encode, runners = runners, gpu = gpu, bits = bits, \n",
    "           btype = btype, ms_init = ms_init)\n",
    "docs_name = f'{load_set}-{len(train_docs)}'\n",
    "ptdocs_name = f'newstweet-{num_posttrain}'\n",
    "data_streams = model.fit(docs, docs_name, covering = covering, all_layers = train_layers, fine_tune = fine_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'form': 8,\n",
       " 'bits': 7,\n",
       " 'sty': 2,\n",
       " 'pos': 6,\n",
       " 'sup': 7,\n",
       " 'dep': 7,\n",
       " 'nov': 2,\n",
       " 'iat': 2,\n",
       " 'bot': 2,\n",
       " 'eot': 2,\n",
       " 'eos': 2,\n",
       " 'eod': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-processed data: 100%|██████████| 1/1 [00:00<00:00, 20460.02it/s]\n",
      "Encoding data streams: 100%|██████████| 1/1 [00:00<00:00, 1242.39it/s]\n",
      "Interpreting documents: 100%|██████████| 1/1 [00:00<00:00, 155.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "opening next doc:\n",
      "opening next sent: decl\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "['\" \"']\n",
      "opening next token: Gone, None, False, X, 0, root\n",
      "['\"Gon\"', '\"e\"']\n",
      "opening next token:  , None, False, SPACE, -1, dep\n",
      "['\" \"']\n",
      "opening next token: again, None, False, PUNCT, -1, punct\n",
      "['\"again\"']\n",
      "opening next token: !, None, True, PUNCT, -1, punct\n",
      "['\"!\"']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.interpret([[' Gone again!']], seed = seed)\n",
    "for doc in model._documents:\n",
    "    print('opening next doc:')\n",
    "    for s in doc._sentences:\n",
    "        print(f'opening next sent: {s._sty}')\n",
    "        for t in s._tokens:\n",
    "            print(f'opening next token: {t._form}, {t._lem}, {t._sep}, {t._pos}, {t._sup}, {t._dep}')\n",
    "            print([\"\\\"\"+w._form+\"\\\"\" for w in t._whatevers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' Emperor Norton ', ' Joshua Abraham Norton (c. 1818 – January 8, 1880), known as Emperor Norton, was a citizen of San Francisco, California, who in 1859 proclaimed himself \"Norton I, Emperor of the United States\". ']]\n",
      "Pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-processed data: 100%|██████████| 1/1 [00:00<00:00, 21399.51it/s]\n",
      "Encoding data streams: 100%|██████████| 1/1 [00:00<00:00, 140.16it/s]\n",
      "Interpreting documents: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 0's STY accuracy:  0.5\n",
      "Document 0's Token segmentation performance without space:  {('F', 0.9782608695652174), ('P', 0.9782608695652174), ('R', 0.9782608695652174)}\n",
      "Document 0's POS accuracy with/out space: 0.7530864197530864 0.5555555555555556\n",
      "Document 0's SUP:DEP accuracy with/out space:  0.4691358024691358 0.1111111111111111\n",
      "\n",
      "Overall sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Overall STY accuracy:  0.5\n",
      "Overall Token segmentation performance without space:  {('F', 0.9782608695652174), ('P', 0.9782608695652174), ('R', 0.9782608695652174)}\n",
      "Overall POS accuracy with/out space: 0.7530864197530864 0.5555555555555556\n",
      "Overall SUP:DEP accuracy with/out space:  0.4691358024691358 0.1111111111111111\n",
      "opening next doc:\n",
      "opening next sent: decl\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: Emperor, None, False, PROPN, 2, vocative\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: Norton, None, False, PROPN, 0, root\n",
      "opening next token:  , None, True, SPACE, -1, space\n",
      "opening next sent: decl\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: Joshua, None, False, VERB, 2, xcomp\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: Abraham, None, False, NOUN, 2, amod\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: Norton, None, False, NOUN, 4, case\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: (, None, False, NOUN, -4, obl\n",
      "opening next token: c, None, False, NOUN, -3, appos\n",
      "opening next token: ., None, False, PUNCT, 2, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: 1818, None, False, PROPN, 2, compound\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: –, None, False, SYM, 4, case\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: January, None, False, PROPN, 2, compound\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: 8, None, False, PROPN, 7, flat\n",
      "opening next token: ,, None, False, PUNCT, 4, punct\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: 1880, None, False, NUM, -3, nmod:tmod\n",
      "opening next token: ), None, False, PUNCT, 5, punct\n",
      "opening next token: ,, None, False, PUNCT, 8, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: known, None, False, PROPN, 2, nsubj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: as, None, False, AUX, 4, conj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: Emperor, None, False, NOUN, 2, conj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: Norton, None, False, NOUN, 2, case\n",
      "opening next token: ,, None, False, PUNCT, 8, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: was, None, False, VERB, 6, cop\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: a, None, False, DET, 4, det\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: citizen, None, False, NOUN, 2, obj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: of, None, False, ADP, 4, case\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: San, None, False, PROPN, 2, compound\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: Francisco, None, False, PROPN, 9, nmod\n",
      "opening next token: ,, None, False, PUNCT, 2, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: California, None, False, PROPN, -3, appos\n",
      "opening next token: ,, None, False, PUNCT, 6, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: who, None, False, PROPN, 2, cc\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: in, None, False, ADP, 4, case\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: 1859, None, False, PROPN, 2, amod\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: proclaimed, None, False, VERB, 0, root\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: himself, None, False, NOUN, 2, obj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: \", None, False, NOUN, -4, obj\n",
      "opening next token: Norton, None, False, NOUN, 4, case\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: I, None, False, PROPN, -4, obl\n",
      "opening next token: ,, None, False, PUNCT, 8, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: Emperor, None, False, PROPN, 6, appos\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: of, None, False, ADP, 6, case\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: the, None, False, DET, 4, det\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: United, None, False, NOUN, 2, nmod\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: States, None, False, NOUN, -16, nmod\n",
      "opening next token: \", None, False, PUNCT, -55, punct\n",
      "opening next token: ., None, False, PUNCT, -62, punct\n",
      "opening next token:  , None, True, SPACE, -64, space\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d_i = 3; s_max = 2\n",
    "interpret_docs = list([docs[d_i][:s_max]])\n",
    "print(interpret_docs)\n",
    "model.interpret(interpret_docs, eval_layers = {0: {tag: train_layers[d_i][tag][:s_max] for tag in train_layers[d_i]}},\n",
    "                eval_covering = [covering[d_i][:s_max]], seed = seed)\n",
    "\n",
    "for doc in model._documents:\n",
    "    print('opening next doc:')\n",
    "    for s in doc._sentences:\n",
    "        print(f'opening next sent: {s._sty}')\n",
    "        for t in s._tokens:\n",
    "            print(f'opening next token: {t._form}, {t._lem}, {t._sep}, {t._pos}, {t._sup}, {t._dep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' The prevalence of discrimination across racial groups in contemporary America: ']]\n",
      "Pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-processed data: 100%|██████████| 1/1 [00:00<00:00, 22192.08it/s]\n",
      "Encoding data streams: 100%|██████████| 1/1 [00:00<00:00, 350.02it/s]\n",
      "Interpreting documents: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 0's STY accuracy:  0.0\n",
      "Document 0's Token segmentation performance without space:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 0's POS accuracy with/out space: 0.6818181818181818 0.36363636363636365\n",
      "Document 0's SUP:DEP accuracy with/out space:  0.5454545454545454 0.2727272727272727\n",
      "\n",
      "Overall sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Overall STY accuracy:  0.0\n",
      "Overall Token segmentation performance without space:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Overall POS accuracy with/out space: 0.6818181818181818 0.36363636363636365\n",
      "Overall SUP:DEP accuracy with/out space:  0.5454545454545454 0.2727272727272727\n",
      "opening next doc:\n",
      "opening next sent: decl\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: The, None, False, PROPN, 2, vocative\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: prevalence, None, False, PROPN, 0, root\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: of, None, False, ADP, 2, flat\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: discrimination, None, False, PROPN, -4, nmod\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: across, None, False, NOUN, -6, amod\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: racial, None, False, NOUN, 2, amod\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: groups, None, False, NOUN, 2, obj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: in, None, False, ADP, -6, case\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: contemporary, None, False, NOUN, -4, nmod\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: America, None, False, PUNCT, -1, dep\n",
      "opening next token: :, None, False, PUNCT, -1, punct\n",
      "opening next token:  , None, True, SPACE, -1, space\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d_i = 0; s_max = 1\n",
    "interpret_docs = list([tdocs[d_i][:s_max]])\n",
    "print(interpret_docs)\n",
    "model.interpret(interpret_docs, eval_layers = {0: {tag: test_layers[d_i][tag][:s_max] for tag in test_layers[d_i]}},\n",
    "                eval_covering = [tcovering[d_i][:s_max]], seed = seed)\n",
    "\n",
    "for doc in model._documents:\n",
    "    print('opening next doc:')\n",
    "    for s in doc._sentences:\n",
    "        print(f'opening next sent: {s._sty}')\n",
    "        for t in s._tokens:\n",
    "            print(f'opening next token: {t._form}, {t._lem}, {t._sep}, {t._pos}, {t._sup}, {t._dep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' 2. GUJJOLAAY EEGIMAA, ITS SPEAKERS AND THEIR NEIGHBOURS ', ' This section briefly presents the Gújjolaay Eegimaa (Eegimaa for short; Ethnologue code: ISO 639-3: bqj), its speakers and its varieties. ']]\n",
      "Pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-processed data: 100%|██████████| 1/1 [00:00<00:00, 21845.33it/s]\n",
      "Encoding data streams: 100%|██████████| 1/1 [00:00<00:00, 77.72it/s]\n",
      "Interpreting documents: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 0's STY accuracy:  0.5\n",
      "Document 0's Token segmentation performance without space:  {('F', 0.6015037593984962), ('P', 0.5128205128205128), ('R', 0.7272727272727273)}\n",
      "Document 0's POS accuracy with/out space: 0.6515151515151515 0.3611111111111111\n",
      "Document 0's SUP:DEP accuracy with/out space:  0.3787878787878788 0.05555555555555555\n",
      "\n",
      "Overall sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Overall STY accuracy:  0.5\n",
      "Overall Token segmentation performance without space:  {('F', 0.6015037593984962), ('P', 0.5128205128205128), ('R', 0.7272727272727273)}\n",
      "Overall POS accuracy with/out space: 0.6515151515151515 0.3611111111111111\n",
      "Overall SUP:DEP accuracy with/out space:  0.3787878787878788 0.05555555555555555\n",
      "opening next doc:\n",
      "opening next sent: decl\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: 2, None, False, PROPN, 5, vocative\n",
      "opening next token: ., None, False, PROPN, 5, vocative\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: G, None, False, PROPN, 1, flat\n",
      "opening next token: U, None, False, PROPN, 0, root\n",
      "opening next token: J, None, False, PUNCT, 2, nsubj\n",
      "opening next token: JO, None, False, PROPN, 2, compound\n",
      "opening next token: LA, None, False, PUNCT, -3, punct\n",
      "opening next token: AY, None, False, PUNCT, 2, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: EE, None, False, PROPN, 2, punct\n",
      "opening next token: GI, None, False, PUNCT, -3, punct\n",
      "opening next token: MA, None, False, NUM, -8, dep\n",
      "opening next token: A, None, False, PROPN, -2, punct\n",
      "opening next token: ,, None, False, PUNCT, -1, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: IT, None, False, PROPN, -3, nsubj\n",
      "opening next token: S, None, False, PUNCT, -1, punct\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: S, None, False, SPACE, 1, space\n",
      "opening next token: P, None, False, PROPN, -2, nsubj\n",
      "opening next token: EA, None, False, PUNCT, -2, punct\n",
      "opening next token: K, None, False, NOUN, 2, punct\n",
      "opening next token: ER, None, False, PUNCT, -2, punct\n",
      "opening next token: S, None, False, PROPN, -1, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: AND, None, False, PROPN, -2, nsubj\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: THE, None, False, NOUN, 2, nsubj\n",
      "opening next token: IR, None, False, PUNCT, -2, punct\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: NE, None, False, PROPN, 2, punct\n",
      "opening next token: IG, None, False, PUNCT, -4, punct\n",
      "opening next token: HB, None, False, PROPN, -4, punct\n",
      "opening next token: OU, None, False, PUNCT, -2, punct\n",
      "opening next token: RS, None, False, PUNCT, -2, punct\n",
      "opening next token:  , None, True, SPACE, -1, space\n",
      "opening next sent: decl\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: This, None, False, NOUN, 2, nsubj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: section, None, False, NOUN, 2, obj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: briefly, None, False, NOUN, 4, nsubj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: presents, None, False, NOUN, 2, case\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: the, None, False, DET, 4, det\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: G, None, False, NOUN, 2, amod\n",
      "opening next token: ú, None, False, PUNCT, 2, punct\n",
      "opening next token: j, None, False, NOUN, 2, compound\n",
      "opening next token: jo, None, False, NOUN, 2, punct\n",
      "opening next token: la, None, False, NOUN, 2, punct\n",
      "opening next token: ay, None, False, NOUN, 2, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: E, None, False, PROPN, 4, nsubj\n",
      "opening next token: e, None, False, ADJ, 2, amod\n",
      "opening next token: g, None, False, VERB, -4, amod\n",
      "opening next token: ima, None, False, NOUN, 2, conj\n",
      "opening next token: a, None, False, NOUN, 2, flat\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: (, None, False, ADJ, 1, amod\n",
      "opening next token: E, None, False, ADV, 2, advmod\n",
      "opening next token: e, None, False, ADJ, -4, amod\n",
      "opening next token: g, None, False, VERB, 0, root\n",
      "opening next token: ima, None, False, NOUN, 1, amod\n",
      "opening next token: a, None, False, NOUN, -2, obj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: for, None, False, ADP, 2, case\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: short, None, False, NOUN, -4, obl\n",
      "opening next token: ;, None, False, PUNCT, -4, punct\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: E, None, False, NOUN, 2, punct\n",
      "opening next token: th, None, False, NOUN, 2, punct\n",
      "opening next token: no, None, False, NOUN, 2, obj\n",
      "opening next token: logue, None, False, VERB, 2, nsubj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: code, None, False, NOUN, 2, punct\n",
      "opening next token: :, None, False, PUNCT, 6, punct\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: IS, None, False, NOUN, 2, punct\n",
      "opening next token: O, None, False, PUNCT, 2, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: 6, None, False, PROPN, 2, punct\n",
      "opening next token: 39, None, False, PUNCT, 2, punct\n",
      "opening next token: -3, None, False, PROPN, 2, punct\n",
      "opening next token: :, None, False, PUNCT, 4, punct\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: b, None, False, PROPN, 2, dep\n",
      "opening next token: q, None, False, PUNCT, 2, punct\n",
      "opening next token: j, None, False, NUM, 2, nmod:tmod\n",
      "opening next token: ), None, False, PUNCT, 9, punct\n",
      "opening next token: ,, None, False, PUNCT, 10, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: its, None, False, PRON, 2, nsubj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: sp, None, False, VERB, -4, amod\n",
      "opening next token: eakers, None, False, NOUN, 2, obj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: and, None, False, CCONJ, -4, cc\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: its, None, False, NOUN, -4, conj\n",
      "opening next token:  , None, False, SPACE, -40, space\n",
      "opening next token: varieties, None, False, PUNCT, -64, punct\n",
      "opening next token: ., None, False, PUNCT, -65, punct\n",
      "opening next token:  , None, True, SPACE, -1, space\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d_i = 1; s_max = 2\n",
    "interpret_docs = list([tdocs[d_i][:s_max]])\n",
    "print(interpret_docs)\n",
    "model.interpret(interpret_docs, eval_layers = {0: {tag: test_layers[d_i][tag][:s_max] for tag in test_layers[d_i]}},\n",
    "                eval_covering = [tcovering[d_i][:s_max]], seed = seed)\n",
    "for doc in model._documents:\n",
    "    print('opening next doc:')\n",
    "    for s in doc._sentences:\n",
    "        print(f'opening next sent: {s._sty}')\n",
    "        for t in s._tokens:\n",
    "            print(f'opening next token: {t._form}, {t._lem}, {t._sep}, {t._pos}, {t._sup}, {t._dep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' 2. GUJJOLAAY EEGIMAA, ITS SPEAKERS AND THEIR NEIGHBOURS ', ' This section briefly presents the Gújjolaay Eegimaa (Eegimaa for short; Ethnologue code: ISO 639-3: bqj), its speakers and its varieties. ']]\n",
      "Pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-processed data: 100%|██████████| 1/1 [00:00<00:00, 21620.12it/s]\n",
      "Encoding data streams: 100%|██████████| 1/1 [00:00<00:00, 104.13it/s]\n",
      "Interpreting documents: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0's STY accuracy:  0.5\n",
      "Document 0's POS accuracy with/out space: 0.7121212121212122 0.4722222222222222\n",
      "Document 0's SUP:DEP accuracy with/out space:  0.3484848484848485 0.0\n",
      "\n",
      "Overall STY accuracy:  0.5\n",
      "Overall POS accuracy with/out space: 0.7121212121212122 0.4722222222222222\n",
      "Overall SUP:DEP accuracy with/out space:  0.3484848484848485 0.0\n",
      "opening next doc:\n",
      "opening next sent: decl\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: 2., None, False, PROPN, 5, vocative\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: GUJJOLAAY, None, False, PROPN, 0, root\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: EEGIMAA, None, False, PROPN, -2, punct\n",
      "opening next token: ,, None, False, PUNCT, -1, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: ITS, None, False, PUNCT, -3, punct\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: SPEAKERS, None, False, PROPN, -1, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: AND, None, False, PROPN, 2, nsubj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: THEIR, None, False, PROPN, -4, punct\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: NEIGHBOURS, None, False, PUNCT, -2, punct\n",
      "opening next token:  , None, True, SPACE, -1, space\n",
      "opening next sent: decl\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: This, None, False, NOUN, 2, nsubj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: section, None, False, NOUN, 2, obj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: briefly, None, False, NOUN, 4, nsubj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: presents, None, False, NOUN, 2, case\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: the, None, False, DET, 6, det\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: Gújjolaay, None, False, NOUN, 2, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: Eegimaa, None, False, NOUN, 2, amod\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: (, None, False, ADJ, 1, amod\n",
      "opening next token: Eegimaa, None, False, VERB, 2, amod\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: for, None, False, ADP, 6, case\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: short, None, False, NOUN, 2, obl\n",
      "opening next token: ;, None, False, PUNCT, -4, punct\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: Ethnologue, None, False, NOUN, 2, nsubj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: code, None, False, NOUN, 0, root\n",
      "opening next token: :, None, False, PUNCT, -2, punct\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: ISO, None, False, PUNCT, 2, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: 639-3, None, False, PROPN, 2, punct\n",
      "opening next token: :, None, False, PUNCT, 4, punct\n",
      "opening next token:  , None, False, SPACE, -1, space\n",
      "opening next token: bqj, None, False, PROPN, 2, punct\n",
      "opening next token: ), None, False, PUNCT, -7, punct\n",
      "opening next token: ,, None, False, PUNCT, -1, punct\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: its, None, False, PRON, 4, nsubj\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: speakers, None, False, NOUN, 2, amod\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: and, None, False, CCONJ, 2, cc\n",
      "opening next token:  , None, False, SPACE, 1, space\n",
      "opening next token: its, None, False, NOUN, -16, conj\n",
      "opening next token:  , None, False, SPACE, -40, space\n",
      "opening next token: varieties, None, False, PUNCT, -40, punct\n",
      "opening next token: ., None, False, PUNCT, -42, punct\n",
      "opening next token:  , None, True, SPACE, -1, space\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d_i = 1; s_max = 2\n",
    "interpret_docs = list([tdocs[d_i][:s_max]])\n",
    "print(interpret_docs)\n",
    "model.interpret(interpret_docs, eval_layers = {0: {tag: test_layers[d_i][tag][:s_max] for tag in test_layers[d_i]}},\n",
    "                covering = [tcovering[d_i][:s_max]], seed = seed)\n",
    "for doc in model._documents:\n",
    "    print('opening next doc:')\n",
    "    for s in doc._sentences:\n",
    "        print(f'opening next sent: {s._sty}')\n",
    "        for t in s._tokens:\n",
    "            print(f'opening next token: {t._form}, {t._lem}, {t._sep}, {t._pos}, {t._sup}, {t._dep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-processed data: 100%|██████████| 18/18 [00:00<00:00, 120602.99it/s]\n",
      "Encoding data streams: 100%|██████████| 18/18 [00:02<00:00,  6.85it/s]\n",
      "Interpreting documents:   6%|▌         | 1/18 [00:15<04:15, 15.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 0's STY accuracy:  0.6851851851851852\n",
      "Document 0's Token segmentation performance without space:  {('F', 0.9181619256017505), ('P', 0.9161572052401746), ('R', 0.9201754385964912)}\n",
      "Document 0's POS accuracy with/out space: 0.7676056338028169 0.560418648905804\n",
      "Document 0's SUP:DEP accuracy with/out space:  0.556841046277666 0.1912464319695528\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  11%|█         | 2/18 [00:35<04:52, 18.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 1's STY accuracy:  0.8611111111111112\n",
      "Document 1's Token segmentation performance without space:  {('F', 0.769850866586054), ('P', 0.7095096582466568), ('R', 0.8414096916299559)}\n",
      "Document 1's POS accuracy with/out space: 0.7576112412177985 0.5394883203559511\n",
      "Document 1's SUP:DEP accuracy with/out space:  0.5327868852459017 0.14015572858731926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  17%|█▋        | 3/18 [00:47<03:50, 15.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 2's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 2's STY accuracy:  0.9310344827586207\n",
      "Document 2's Token segmentation performance without space:  {('F', 0.8203939745075318), ('P', 0.7823204419889502), ('R', 0.8623629719853837)}\n",
      "Document 2's POS accuracy with/out space: 0.7596958174904943 0.5459770114942529\n",
      "Document 2's SUP:DEP accuracy with/out space:  0.5498098859315589 0.1781609195402299\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  22%|██▏       | 4/18 [01:04<03:42, 15.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 3's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 3's STY accuracy:  0.9\n",
      "Document 3's Token segmentation performance without space:  {('F', 0.8661347517730497), ('P', 0.8466204506065858), ('R', 0.8865698729582577)}\n",
      "Document 3's POS accuracy with/out space: 0.7895299145299145 0.5991861648016277\n",
      "Document 3's SUP:DEP accuracy with/out space:  0.5715811965811965 0.20040691759918616\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  28%|██▊       | 5/18 [01:10<02:43, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 4's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 4's STY accuracy:  0.46078431372549017\n",
      "Document 4's Token segmentation performance without space:  {('F', 0.9085992428339643), ('P', 0.9130434782608695), ('R', 0.9041980624327234)}\n",
      "Document 4's POS accuracy with/out space: 0.7869458128078818 0.5988372093023255\n",
      "Document 4's SUP:DEP accuracy with/out space:  0.5899014778325123 0.2453488372093023\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  33%|███▎      | 6/18 [01:22<02:27, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 5's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 5's STY accuracy:  0.7894736842105263\n",
      "Document 5's Token segmentation performance without space:  {('F', 0.8612068965517242), ('P', 0.84375), ('R', 0.8794014084507042)}\n",
      "Document 5's POS accuracy with/out space: 0.7538298996302166 0.5404339250493096\n",
      "Document 5's SUP:DEP accuracy with/out space:  0.5499207606973059 0.1932938856015779\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  39%|███▉      | 7/18 [01:37<02:25, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 6's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 6's STY accuracy:  0.9148936170212766\n",
      "Document 6's Token segmentation performance without space:  {('F', 0.8839015968925336), ('P', 0.8767123287671232), ('R', 0.8912097476066144)}\n",
      "Document 6's POS accuracy with/out space: 0.7520576131687243 0.5251231527093596\n",
      "Document 6's SUP:DEP accuracy with/out space:  0.5457818930041153 0.15467980295566502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  44%|████▍     | 8/18 [01:45<01:53, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 7's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 7's STY accuracy:  0.5344827586206896\n",
      "Document 7's Token segmentation performance without space:  {('F', 0.8993885491939967), ('P', 0.88998899889989), ('R', 0.9089887640449438)}\n",
      "Document 7's POS accuracy with/out space: 0.7919038583175205 0.5923172242874845\n",
      "Document 7's SUP:DEP accuracy with/out space:  0.58191018342821 0.20817843866171004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  50%|█████     | 9/18 [01:58<01:48, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 8's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 8's STY accuracy:  0.5952380952380952\n",
      "Document 8's Token segmentation performance without space:  {('F', 0.856425702811245), ('P', 0.8305744888023369), ('R', 0.883937823834197)}\n",
      "Document 8's POS accuracy with/out space: 0.7552404438964242 0.5307328605200946\n",
      "Document 8's SUP:DEP accuracy with/out space:  0.5443896424167695 0.15011820330969267\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  56%|█████▌    | 10/18 [02:19<01:58, 14.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 9's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 9's STY accuracy:  0.72\n",
      "Document 9's Token segmentation performance without space:  {('F', 0.8424611223799865), ('P', 0.8218997361477572), ('R', 0.8640776699029126)}\n",
      "Document 9's POS accuracy with/out space: 0.7712743877127439 0.5647709320695102\n",
      "Document 9's SUP:DEP accuracy with/out space:  0.5396430053964301 0.1524486571879937\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  61%|██████    | 11/18 [02:28<01:31, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 10's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 10's STY accuracy:  0.5428571428571428\n",
      "Document 10's Token segmentation performance without space:  {('F', 0.8525951557093426), ('P', 0.8380952380952381), ('R', 0.8676056338028169)}\n",
      "Document 10's POS accuracy with/out space: 0.7667785234899329 0.5552\n",
      "Document 10's SUP:DEP accuracy with/out space:  0.5444630872483222 0.1696\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  67%|██████▋   | 12/18 [02:42<01:18, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 11's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 11's STY accuracy:  0.8181818181818182\n",
      "Document 11's Token segmentation performance without space:  {('F', 0.878585086042065), ('P', 0.8556797020484171), ('R', 0.9027504911591355)}\n",
      "Document 11's POS accuracy with/out space: 0.7810055865921788 0.5726775956284152\n",
      "Document 11's SUP:DEP accuracy with/out space:  0.5810055865921788 0.1901639344262295\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  72%|███████▏  | 13/18 [02:55<01:05, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 12's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 12's STY accuracy:  0.6545454545454545\n",
      "Document 12's Token segmentation performance without space:  {('F', 0.8613333333333334), ('P', 0.8426086956521739), ('R', 0.8809090909090909)}\n",
      "Document 12's POS accuracy with/out space: 0.7636856368563686 0.5544147843942505\n",
      "Document 12's SUP:DEP accuracy with/out space:  0.5344173441734418 0.14989733059548255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  78%|███████▊  | 14/18 [03:06<00:49, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 13's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 13's STY accuracy:  0.4418604651162791\n",
      "Document 13's Token segmentation performance without space:  {('F', 0.9105018106570099), ('P', 0.9081527347781218), ('R', 0.9128630705394191)}\n",
      "Document 13's POS accuracy with/out space: 0.7620429483459082 0.5444444444444444\n",
      "Document 13's SUP:DEP accuracy with/out space:  0.5461404526987812 0.1511111111111111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  83%|████████▎ | 15/18 [03:27<00:45, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 14's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 14's STY accuracy:  0.8918918918918919\n",
      "Document 14's Token segmentation performance without space:  {('F', 0.8788484606157536), ('P', 0.8687747035573122), ('R', 0.88915857605178)}\n",
      "Document 14's POS accuracy with/out space: 0.7784688995215311 0.577939835916135\n",
      "Document 14's SUP:DEP accuracy with/out space:  0.5574162679425837 0.1741112123974476\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  89%|████████▉ | 16/18 [03:36<00:26, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 15's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 15's STY accuracy:  0.8421052631578947\n",
      "Document 15's Token segmentation performance without space:  {('F', 0.8513157894736841), ('P', 0.8252551020408163), ('R', 0.8790760869565217)}\n",
      "Document 15's POS accuracy with/out space: 0.7866449511400652 0.5808\n",
      "Document 15's SUP:DEP accuracy with/out space:  0.5814332247557004 0.1936\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  94%|█████████▍| 17/18 [03:43<00:11, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 16's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 16's STY accuracy:  0.32558139534883723\n",
      "Document 16's Token segmentation performance without space:  {('F', 0.9072164948453609), ('P', 0.9004092769440655), ('R', 0.9141274238227147)}\n",
      "Document 16's POS accuracy with/out space: 0.7850911974623315 0.5826893353941267\n",
      "Document 16's SUP:DEP accuracy with/out space:  0.5860428231562252 0.21792890262751158\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents: 100%|██████████| 18/18 [03:53<00:00, 12.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 17's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 17's STY accuracy:  0.4153846153846154\n",
      "Document 17's Token segmentation performance without space:  {('F', 0.908675799086758), ('P', 0.898014440433213), ('R', 0.9195933456561922)}\n",
      "Document 17's POS accuracy with/out space: 0.8134981968057702 0.6365461847389559\n",
      "Document 17's SUP:DEP accuracy with/out space:  0.5734157650695518 0.19477911646586346\n",
      "\n",
      "Overall sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Overall STY accuracy:  0.6588366890380313\n",
      "Overall Token segmentation performance without space:  {('F', 0.8694372340710215), ('P', 0.850879949717159), ('R', 0.8888220167423537)}\n",
      "Overall POS accuracy with/out space: 0.7733836137433121 0.5667242229896399\n",
      "Overall SUP:DEP accuracy with/out space:  0.558241474892026 0.17939072520966945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.interpret(tdocs, eval_layers = test_layers, eval_covering = tcovering, seed = seed, verbose_result = False, \n",
    "                decode_method = decode_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-processed data: 100%|██████████| 18/18 [00:00<00:00, 285975.27it/s]\n",
      "Encoding data streams: 100%|██████████| 18/18 [00:02<00:00,  6.21it/s]\n",
      "Interpreting documents:   6%|▌         | 1/18 [00:13<03:43, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0's STY accuracy:  0.6851851851851852\n",
      "Document 0's POS accuracy with/out space: 0.7917505030181087 0.6060894386298763\n",
      "Document 0's SUP:DEP accuracy with/out space:  0.5653923541247485 0.20456707897240722\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  11%|█         | 2/18 [00:25<03:26, 12.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1's STY accuracy:  0.8611111111111112\n",
      "Document 1's POS accuracy with/out space: 0.7933255269320844 0.60734149054505\n",
      "Document 1's SUP:DEP accuracy with/out space:  0.5374707259953162 0.14015572858731926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  17%|█▋        | 3/18 [00:34<02:43, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 2's STY accuracy:  0.9310344827586207\n",
      "Document 2's POS accuracy with/out space: 0.7802281368821293 0.5847701149425287\n",
      "Document 2's SUP:DEP accuracy with/out space:  0.5467680608365019 0.1724137931034483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  22%|██▏       | 4/18 [00:48<02:49, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 3's STY accuracy:  0.9\n",
      "Document 3's POS accuracy with/out space: 0.8092948717948718 0.6368260427263479\n",
      "Document 3's SUP:DEP accuracy with/out space:  0.5731837606837606 0.20244150559511698\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  28%|██▊       | 5/18 [00:54<02:07,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 4's STY accuracy:  0.46078431372549017\n",
      "Document 4's POS accuracy with/out space: 0.8183497536945813 0.6581395348837209\n",
      "Document 4's SUP:DEP accuracy with/out space:  0.6016009852216748 0.26976744186046514\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  33%|███▎      | 6/18 [01:03<01:57,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 5's STY accuracy:  0.7894736842105263\n",
      "Document 5's POS accuracy with/out space: 0.7897517168515584 0.6074950690335306\n",
      "Document 5's SUP:DEP accuracy with/out space:  0.5567881669307977 0.20512820512820512\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  39%|███▉      | 7/18 [01:17<01:59, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 6's STY accuracy:  0.9148936170212766\n",
      "Document 6's POS accuracy with/out space: 0.7870370370370371 0.5921182266009852\n",
      "Document 6's SUP:DEP accuracy with/out space:  0.5524691358024691 0.16551724137931034\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  44%|████▍     | 8/18 [01:23<01:35,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 7's STY accuracy:  0.5344827586206896\n",
      "Document 7's POS accuracy with/out space: 0.8121442125237192 0.6319702602230484\n",
      "Document 7's SUP:DEP accuracy with/out space:  0.592662871600253 0.23172242874845106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  50%|█████     | 9/18 [01:34<01:29,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 8's STY accuracy:  0.5952380952380952\n",
      "Document 8's POS accuracy with/out space: 0.781750924784217 0.5815602836879432\n",
      "Document 8's SUP:DEP accuracy with/out space:  0.5530209617755857 0.1690307328605201\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  56%|█████▌    | 10/18 [01:51<01:37, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 9's STY accuracy:  0.72\n",
      "Document 9's POS accuracy with/out space: 0.7995018679950187 0.6184834123222749\n",
      "Document 9's SUP:DEP accuracy with/out space:  0.5579078455790785 0.18404423380726698\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  61%|██████    | 11/18 [01:59<01:15, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 10's STY accuracy:  0.5428571428571428\n",
      "Document 10's POS accuracy with/out space: 0.7969798657718121 0.6128\n",
      "Document 10's SUP:DEP accuracy with/out space:  0.5486577181208053 0.1776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  67%|██████▋   | 12/18 [02:10<01:05, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 11's STY accuracy:  0.8181818181818182\n",
      "Document 11's POS accuracy with/out space: 0.8016759776536313 0.6131147540983607\n",
      "Document 11's SUP:DEP accuracy with/out space:  0.5865921787709497 0.2010928961748634\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  72%|███████▏  | 13/18 [02:21<00:55, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 12's STY accuracy:  0.6545454545454545\n",
      "Document 12's POS accuracy with/out space: 0.7821138211382114 0.5893223819301848\n",
      "Document 12's SUP:DEP accuracy with/out space:  0.5506775067750678 0.1735112936344969\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  78%|███████▊  | 14/18 [02:32<00:43, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 13's STY accuracy:  0.4418604651162791\n",
      "Document 13's POS accuracy with/out space: 0.7858386535113174 0.59\n",
      "Document 13's SUP:DEP accuracy with/out space:  0.5461404526987812 0.15333333333333332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  83%|████████▎ | 15/18 [02:50<00:39, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 14's STY accuracy:  0.8918918918918919\n",
      "Document 14's POS accuracy with/out space: 0.7995215311004785 0.618049225159526\n",
      "Document 14's SUP:DEP accuracy with/out space:  0.5511961722488038 0.1649954421148587\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  89%|████████▉ | 16/18 [02:56<00:22, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 15's STY accuracy:  0.8421052631578947\n",
      "Document 15's POS accuracy with/out space: 0.8281758957654723 0.6624\n",
      "Document 15's SUP:DEP accuracy with/out space:  0.5806188925081434 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  94%|█████████▍| 17/18 [03:03<00:09,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 16's STY accuracy:  0.32558139534883723\n",
      "Document 16's POS accuracy with/out space: 0.8049167327517843 0.6213292117465224\n",
      "Document 16's SUP:DEP accuracy with/out space:  0.5828707375099128 0.23183925811437403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents: 100%|██████████| 18/18 [03:11<00:00, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 17's STY accuracy:  0.4153846153846154\n",
      "Document 17's POS accuracy with/out space: 0.8444100978876867 0.6967871485943775\n",
      "Document 17's SUP:DEP accuracy with/out space:  0.5821741370427614 0.20983935742971888\n",
      "\n",
      "Overall STY accuracy:  0.6588366890380313\n",
      "Overall POS accuracy with/out space: 0.8001676013665957 0.6179699062654169\n",
      "Overall SUP:DEP accuracy with/out space:  0.5643009089151034 0.1910458806117415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.interpret(tdocs, eval_layers = test_layers, covering = tcovering, seed = seed, verbose_result = False, \n",
    "                decode_method = decode_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing: 100%|██████████| 7503/7503 [00:09<00:00, 779.00it/s]\n",
      "Fitting:  14%|█▍        | 14/100 [02:35<15:54, 11.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built a vocabulary of 41538 types\n",
      "Pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-processed data: 100%|██████████| 1132/1132 [00:00<00:00, 2831217.73it/s]\n",
      "Counting tag-tag transition frequencies: 100%|██████████| 1132/1132 [00:01<00:00, 676.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting documents and aggregating counts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting aggregated counts: 11229394it [10:44, 17426.61it/s]\n",
      "Encoding parameters: 100%|██████████| 11229394/11229394 [02:09<00:00, 86639.13it/s]\n",
      "Building target vocabularies: 100%|██████████| 23/23 [00:00<00:00, 930.87it/s]\n",
      "Stacking output vocabularies for decoders: 100%|██████████| 11/11 [00:00<00:00, 92645.27it/s]\n",
      "Building dense decoders: 100%|██████████| 23/23 [00:00<00:00, 34.82it/s]\n",
      "Building transition matrices for tag-sequence decoding: 100%|██████████| 7/7 [00:00<00:00, 3192.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params, types, encoding size, contexts, vec dim, max sent, and % capacity used: 2100689 10300 50 1071 353 18310 21.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_ = model.fit(ptdocs, ptdocs_name, update = update, fine_tune = fine_tune, bits = bits)\n",
    "if fine_tune and ptdocs:\n",
    "    model.fine_tune(docs, covering = covering, all_layers = train_layers, streams = data_streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-processed data: 100%|██████████| 18/18 [00:00<00:00, 285975.27it/s]\n",
      "Encoding data streams: 100%|██████████| 18/18 [00:02<00:00,  7.21it/s]\n",
      "Interpreting documents:   6%|▌         | 1/18 [00:14<04:02, 14.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 0's STY accuracy:  0.6851851851851852\n",
      "Document 0's Token segmentation performance without space:  {('F', 0.9302325581395349), ('P', 0.9340659340659341), ('R', 0.9264305177111717)}\n",
      "Document 0's POS accuracy with/out space: 0.7701207243460765 0.5651760228353948\n",
      "Document 0's SUP:DEP accuracy with/out space:  0.5628772635814889 0.19695528068506185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  11%|█         | 2/18 [00:34<04:45, 17.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 1's STY accuracy:  0.8611111111111112\n",
      "Document 1's Token segmentation performance without space:  {('F', 0.7701102490812577), ('P', 0.7165653495440729), ('R', 0.8323036187113857)}\n",
      "Document 1's POS accuracy with/out space: 0.7464871194379391 0.5183537263626251\n",
      "Document 1's SUP:DEP accuracy with/out space:  0.5415690866510539 0.15016685205784205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  17%|█▋        | 3/18 [00:45<03:42, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 2's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 2's STY accuracy:  0.9310344827586207\n",
      "Document 2's Token segmentation performance without space:  {('F', 0.8422315536892621), ('P', 0.8059701492537313), ('R', 0.8819095477386935)}\n",
      "Document 2's POS accuracy with/out space: 0.75893536121673 0.5445402298850575\n",
      "Document 2's SUP:DEP accuracy with/out space:  0.5460076045627377 0.16666666666666666\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  22%|██▏       | 4/18 [01:02<03:35, 15.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 3's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 3's STY accuracy:  0.9\n",
      "Document 3's Token segmentation performance without space:  {('F', 0.891818181818182), ('P', 0.8782452999104745), ('R', 0.9058171745152355)}\n",
      "Document 3's POS accuracy with/out space: 0.7964743589743589 0.612410986775178\n",
      "Document 3's SUP:DEP accuracy with/out space:  0.5662393162393162 0.19023397761953204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  28%|██▊       | 5/18 [01:09<02:41, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 4's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 4's STY accuracy:  0.46078431372549017\n",
      "Document 4's Token segmentation performance without space:  {('F', 0.920265780730897), ('P', 0.9305711086226204), ('R', 0.9101861993428259)}\n",
      "Document 4's POS accuracy with/out space: 0.7752463054187192 0.5755813953488372\n",
      "Document 4's SUP:DEP accuracy with/out space:  0.5880541871921182 0.23604651162790696\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  33%|███▎      | 6/18 [01:20<02:23, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 5's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 5's STY accuracy:  0.7894736842105263\n",
      "Document 5's Token segmentation performance without space:  {('F', 0.8806437192668753), ('P', 0.8701413427561837), ('R', 0.8914027149321267)}\n",
      "Document 5's POS accuracy with/out space: 0.751188589540412 0.5355029585798816\n",
      "Document 5's SUP:DEP accuracy with/out space:  0.5388272583201268 0.1765285996055227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  39%|███▉      | 7/18 [01:35<02:21, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 6's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 6's STY accuracy:  0.9148936170212766\n",
      "Document 6's Token segmentation performance without space:  {('F', 0.8912561029738126), ('P', 0.8822495606326889), ('R', 0.9004484304932735)}\n",
      "Document 6's POS accuracy with/out space: 0.7566872427983539 0.5339901477832513\n",
      "Document 6's SUP:DEP accuracy with/out space:  0.5498971193415638 0.15566502463054188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  44%|████▍     | 8/18 [01:42<01:50, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 7's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 7's STY accuracy:  0.5344827586206896\n",
      "Document 7's Token segmentation performance without space:  {('F', 0.9230769230769231), ('P', 0.9130434782608695), ('R', 0.9333333333333333)}\n",
      "Document 7's POS accuracy with/out space: 0.8070841239721696 0.6220570012391574\n",
      "Document 7's SUP:DEP accuracy with/out space:  0.58191018342821 0.20446096654275092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  50%|█████     | 9/18 [01:54<01:43, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 8's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 8's STY accuracy:  0.5952380952380952\n",
      "Document 8's Token segmentation performance without space:  {('F', 0.9017525225703665), ('P', 0.9003181336161188), ('R', 0.9031914893617021)}\n",
      "Document 8's POS accuracy with/out space: 0.7620221948212084 0.5437352245862884\n",
      "Document 8's SUP:DEP accuracy with/out space:  0.5487053020961775 0.1453900709219858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  56%|█████▌    | 10/18 [02:14<01:51, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 9's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 9's STY accuracy:  0.72\n",
      "Document 9's Token segmentation performance without space:  {('F', 0.8847663217980736), ('P', 0.8831908831908832), ('R', 0.8863473909935669)}\n",
      "Document 9's POS accuracy with/out space: 0.7779161477791615 0.5774091627172195\n",
      "Document 9's SUP:DEP accuracy with/out space:  0.5425487754254877 0.14691943127962084\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  61%|██████    | 11/18 [02:22<01:25, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 10's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 10's STY accuracy:  0.5428571428571428\n",
      "Document 10's Token segmentation performance without space:  {('F', 0.8845878136200718), ('P', 0.8814285714285715), ('R', 0.8877697841726618)}\n",
      "Document 10's POS accuracy with/out space: 0.764261744966443 0.5504\n",
      "Document 10's SUP:DEP accuracy with/out space:  0.5385906040268457 0.1504\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  67%|██████▋   | 12/18 [02:34<01:13, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 11's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 11's STY accuracy:  0.8181818181818182\n",
      "Document 11's Token segmentation performance without space:  {('F', 0.9363636363636363), ('P', 0.9325955734406438), ('R', 0.9401622718052738)}\n",
      "Document 11's POS accuracy with/out space: 0.7787709497206704 0.5672131147540984\n",
      "Document 11's SUP:DEP accuracy with/out space:  0.5782122905027933 0.18579234972677597\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  72%|███████▏  | 13/18 [02:46<01:01, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 12's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 12's STY accuracy:  0.6545454545454545\n",
      "Document 12's Token segmentation performance without space:  {('F', 0.8991248272685399), ('P', 0.8945921173235564), ('R', 0.9037037037037037)}\n",
      "Document 12's POS accuracy with/out space: 0.759349593495935 0.5462012320328542\n",
      "Document 12's SUP:DEP accuracy with/out space:  0.5425474254742547 0.162217659137577\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  78%|███████▊  | 14/18 [02:57<00:47, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 13's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 13's STY accuracy:  0.4418604651162791\n",
      "Document 13's Token segmentation performance without space:  {('F', 0.9250780437044746), ('P', 0.9299163179916318), ('R', 0.9202898550724637)}\n",
      "Document 13's POS accuracy with/out space: 0.75507835171213 0.5311111111111111\n",
      "Document 13's SUP:DEP accuracy with/out space:  0.5449796865931514 0.14777777777777779\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  83%|████████▎ | 15/18 [03:19<00:44, 14.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 14's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 14's STY accuracy:  0.8918918918918919\n",
      "Document 14's Token segmentation performance without space:  {('F', 0.8932515337423313), ('P', 0.8899755501222494), ('R', 0.896551724137931)}\n",
      "Document 14's POS accuracy with/out space: 0.777511961722488 0.5761166818596172\n",
      "Document 14's SUP:DEP accuracy with/out space:  0.5502392344497608 0.16043755697356427\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  89%|████████▉ | 16/18 [03:27<00:25, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 15's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 15's STY accuracy:  0.8421052631578947\n",
      "Document 15's Token segmentation performance without space:  {('F', 0.823529411764706), ('P', 0.7952559300873908), ('R', 0.853887399463807)}\n",
      "Document 15's POS accuracy with/out space: 0.7760586319218241 0.56\n",
      "Document 15's SUP:DEP accuracy with/out space:  0.5732899022801303 0.1744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  94%|█████████▍| 17/18 [03:35<00:11, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 16's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 16's STY accuracy:  0.32558139534883723\n",
      "Document 16's Token segmentation performance without space:  {('F', 0.9004871259568545), ('P', 0.8850889192886456), ('R', 0.9164305949008499)}\n",
      "Document 16's POS accuracy with/out space: 0.7922283901665345 0.5950540958268934\n",
      "Document 16's SUP:DEP accuracy with/out space:  0.5836637589214909 0.2071097372488408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents: 100%|██████████| 18/18 [03:44<00:00, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 17's Sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Document 17's STY accuracy:  0.4153846153846154\n",
      "Document 17's Token segmentation performance without space:  {('F', 0.9170549860205033), ('P', 0.9085872576177285), ('R', 0.9256820319849483)}\n",
      "Document 17's POS accuracy with/out space: 0.8088614116434827 0.6275100401606426\n",
      "Document 17's SUP:DEP accuracy with/out space:  0.5692941782586296 0.18373493975903615\n",
      "\n",
      "Overall sentence segmentation performance:  {('R', 1.0), ('P', 1.0), ('F', 1.0)}\n",
      "Overall STY accuracy:  0.6588366890380313\n",
      "Overall Token segmentation performance without space:  {('F', 0.889170780134021), ('P', 0.8779611174644666), ('R', 0.9006703910614525)}\n",
      "Overall POS accuracy with/out space: 0.7731257654870108 0.5660458806117414\n",
      "Overall SUP:DEP accuracy with/out space:  0.5574356990910849 0.17365564874198322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if ptdocs:\n",
    "    model.interpret(tdocs, eval_layers = test_layers, eval_covering = tcovering, seed = seed, verbose_result = False, \n",
    "                    decode_method = decode_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-processed data: 100%|██████████| 18/18 [00:00<00:00, 140853.49it/s]\n",
      "Encoding data streams: 100%|██████████| 18/18 [00:02<00:00,  7.34it/s]\n",
      "Interpreting documents:   6%|▌         | 1/18 [00:12<03:40, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0's STY accuracy:  0.6851851851851852\n",
      "Document 0's POS accuracy with/out space: 0.7852112676056338 0.5937202664129401\n",
      "Document 0's SUP:DEP accuracy with/out space:  0.5699195171026157 0.2093244529019981\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  11%|█         | 2/18 [00:25<03:25, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1's STY accuracy:  0.8611111111111112\n",
      "Document 1's POS accuracy with/out space: 0.7792740046838408 0.5806451612903226\n",
      "Document 1's SUP:DEP accuracy with/out space:  0.5298594847775175 0.12458286985539488\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  17%|█▋        | 3/18 [00:34<02:45, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 2's STY accuracy:  0.9310344827586207\n",
      "Document 2's POS accuracy with/out space: 0.7878326996197719 0.5991379310344828\n",
      "Document 2's SUP:DEP accuracy with/out space:  0.5475285171102662 0.17385057471264367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  22%|██▏       | 4/18 [00:48<02:49, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 3's STY accuracy:  0.9\n",
      "Document 3's POS accuracy with/out space: 0.811965811965812 0.641912512716175\n",
      "Document 3's SUP:DEP accuracy with/out space:  0.5673076923076923 0.19023397761953204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  28%|██▊       | 5/18 [00:54<02:07,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 4's STY accuracy:  0.46078431372549017\n",
      "Document 4's POS accuracy with/out space: 0.8054187192118226 0.6325581395348837\n",
      "Document 4's SUP:DEP accuracy with/out space:  0.603448275862069 0.26627906976744187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  33%|███▎      | 6/18 [01:03<01:56,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 5's STY accuracy:  0.7894736842105263\n",
      "Document 5's POS accuracy with/out space: 0.7765451664025357 0.5828402366863905\n",
      "Document 5's SUP:DEP accuracy with/out space:  0.5467511885895404 0.1893491124260355\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  39%|███▉      | 7/18 [01:16<01:58, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 6's STY accuracy:  0.9148936170212766\n",
      "Document 6's POS accuracy with/out space: 0.7880658436213992 0.594088669950739\n",
      "Document 6's SUP:DEP accuracy with/out space:  0.5550411522633745 0.1684729064039409\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  44%|████▍     | 8/18 [01:23<01:34,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 7's STY accuracy:  0.5344827586206896\n",
      "Document 7's POS accuracy with/out space: 0.8222643896268185 0.6517967781908303\n",
      "Document 7's SUP:DEP accuracy with/out space:  0.5939278937381404 0.2218091697645601\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  50%|█████     | 9/18 [01:33<01:28,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 8's STY accuracy:  0.5952380952380952\n",
      "Document 8's POS accuracy with/out space: 0.7842170160295932 0.5862884160756501\n",
      "Document 8's SUP:DEP accuracy with/out space:  0.5561035758323057 0.1595744680851064\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  56%|█████▌    | 10/18 [01:52<01:39, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 9's STY accuracy:  0.72\n",
      "Document 9's POS accuracy with/out space: 0.7986716479867165 0.6169036334913112\n",
      "Document 9's SUP:DEP accuracy with/out space:  0.5529265255292652 0.16429699842022116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  61%|██████    | 11/18 [01:59<01:16, 10.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 10's STY accuracy:  0.5428571428571428\n",
      "Document 10's POS accuracy with/out space: 0.7953020134228188 0.6096\n",
      "Document 10's SUP:DEP accuracy with/out space:  0.5503355704697986 0.1776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  67%|██████▋   | 12/18 [02:10<01:06, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 11's STY accuracy:  0.8181818181818182\n",
      "Document 11's POS accuracy with/out space: 0.7910614525139665 0.5912568306010929\n",
      "Document 11's SUP:DEP accuracy with/out space:  0.5787709497206703 0.18469945355191256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  72%|███████▏  | 13/18 [02:21<00:54, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 12's STY accuracy:  0.6545454545454545\n",
      "Document 12's POS accuracy with/out space: 0.775609756097561 0.5770020533880903\n",
      "Document 12's SUP:DEP accuracy with/out space:  0.5495934959349593 0.175564681724846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  78%|███████▊  | 14/18 [02:32<00:43, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 13's STY accuracy:  0.4418604651162791\n",
      "Document 13's POS accuracy with/out space: 0.7800348229831688 0.5788888888888889\n",
      "Document 13's SUP:DEP accuracy with/out space:  0.5536854323853744 0.1622222222222222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  83%|████████▎ | 15/18 [02:50<00:39, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 14's STY accuracy:  0.8918918918918919\n",
      "Document 14's POS accuracy with/out space: 0.792822966507177 0.6052871467639015\n",
      "Document 14's SUP:DEP accuracy with/out space:  0.554066985645933 0.16681859617137648\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  89%|████████▉ | 16/18 [02:56<00:22, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 15's STY accuracy:  0.8421052631578947\n",
      "Document 15's POS accuracy with/out space: 0.8298045602605864 0.6656\n",
      "Document 15's SUP:DEP accuracy with/out space:  0.5781758957654723 0.1872\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents:  94%|█████████▍| 17/18 [03:03<00:09,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 16's STY accuracy:  0.32558139534883723\n",
      "Document 16's POS accuracy with/out space: 0.8112609040444092 0.6321483771251932\n",
      "Document 16's SUP:DEP accuracy with/out space:  0.5900079302141158 0.22565687789799072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreting documents: 100%|██████████| 18/18 [03:11<00:00, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 17's STY accuracy:  0.4153846153846154\n",
      "Document 17's POS accuracy with/out space: 0.8397733127253992 0.6877510040160643\n",
      "Document 17's SUP:DEP accuracy with/out space:  0.5790829469345699 0.20281124497991967\n",
      "\n",
      "Overall STY accuracy:  0.6588366890380313\n",
      "Overall POS accuracy with/out space: 0.7968155740346806 0.6113714849531328\n",
      "Overall SUP:DEP accuracy with/out space:  0.5634951331141623 0.18494079921065615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if ptdocs:\n",
    "    model.interpret(tdocs, eval_layers = test_layers, covering = tcovering, seed = seed, verbose_result = False, \n",
    "                    decode_method = decode_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
